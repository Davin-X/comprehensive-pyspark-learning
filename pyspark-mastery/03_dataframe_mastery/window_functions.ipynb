{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü™ü Window Functions: Advanced Analytical Operations\n",
    "\n",
    "**Time to complete:** 40 minutes  \n",
    "**Difficulty:** Advanced  \n",
    "**Prerequisites:** DataFrame basics, aggregations\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will master:\n",
    "- ‚úÖ **Window functions** - Row-based analytical operations\n",
    "- ‚úÖ **Ranking functions** - rank(), dense_rank(), row_number()\n",
    "- ‚úÖ **Aggregate over windows** - running totals, moving averages\n",
    "- ‚úÖ **Lag/Lead functions** - Access previous/next rows\n",
    "- ‚úÖ **Complex window specifications** - PARTITION BY, ORDER BY, frame clauses\n",
    "- ‚úÖ **Performance optimization** - Efficient window operations\n",
    "\n",
    "**Window functions are essential for advanced analytics and time-series analysis!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Understanding Window Functions\n",
    "\n",
    "**Window functions** perform calculations across sets of rows that are related to the current row. Unlike aggregations that group rows, window functions maintain all rows while adding analytical columns.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Window**: Set of rows to analyze\n",
    "- **Partition**: How to group rows (like GROUP BY)\n",
    "- **Order**: How to sort rows within partitions\n",
    "- **Frame**: Which rows within the partition to consider\n",
    "\n",
    "### Window Function Syntax:\n",
    "```sql\n",
    "window_function() OVER (\n",
    "    PARTITION BY column1, column2     -- Group rows\n",
    "    ORDER BY column3                  -- Sort within groups  \n",
    "    ROWS BETWEEN start AND end        -- Define frame\n",
    ")\n",
    "```\n",
    "\n",
    "**Window functions are computed after aggregations but before final ORDER BY.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, row_number, rank, dense_rank, lag, lead\n",
    "from pyspark.sql.functions import sum, avg, min, max, count\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Window_Functions\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"‚úÖ Spark ready - Version: {spark.version}\")\n",
    "\n",
    "# Create comprehensive sales data with time component\n",
    "sales_data = [\n",
    "    (\"Alice\", \"North\", \"Electronics\", 1200, \"2023-01-15\"),\n",
    "    (\"Bob\", \"South\", \"Electronics\", 800, \"2023-01-16\"),\n",
    "    (\"Alice\", \"North\", \"Clothing\", 300, \"2023-01-17\"),\n",
    "    (\"Charlie\", \"East\", \"Electronics\", 1500, \"2023-01-18\"),\n",
    "    (\"Alice\", \"North\", \"Electronics\", 900, \"2023-01-19\"),\n",
    "    (\"Bob\", \"South\", \"Clothing\", 450, \"2023-01-20\"),\n",
    "    (\"Diana\", \"West\", \"Electronics\", 1300, \"2023-01-21\"),\n",
    "    (\"Charlie\", \"East\", \"Clothing\", 600, \"2023-01-22\"),\n",
    "    (\"Alice\", \"North\", \"Books\", 150, \"2023-01-23\"),\n",
    "    (\"Bob\", \"South\", \"Books\", 200, \"2023-01-24\"),\n",
    "    # February data\n",
    "    (\"Alice\", \"North\", \"Electronics\", 1400, \"2023-02-01\"),\n",
    "    (\"Charlie\", \"East\", \"Electronics\", 1600, \"2023-02-02\"),\n",
    "    (\"Bob\", \"South\", \"Electronics\", 1100, \"2023-02-03\"),\n",
    "    (\"Diana\", \"West\", \"Clothing\", 800, \"2023-02-04\"),\n",
    "    (\"Alice\", \"North\", \"Clothing\", 500, \"2023-02-05\")\n",
    "]\n",
    "\n",
    "sales_df = spark.createDataFrame(\n",
    "    sales_data, \n",
    "    [\"salesperson\", \"region\", \"category\", \"amount\", \"date\"]\n",
    ")\n",
    "\n",
    "print(\"üìä Sales Dataset:\")\n",
    "sales_df.orderBy(\"date\").show()\n",
    "print(f\"Total records: {sales_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Ranking Functions\n",
    "\n",
    "### Row Number, Rank, and Dense Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking functions\n",
    "print(\"üèÜ RANKING FUNCTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define window specifications\n",
    "by_region_amount = Window.partitionBy(\"region\").orderBy(col(\"amount\").desc())\n",
    "by_salesperson_date = Window.partitionBy(\"salesperson\").orderBy(\"date\")\n",
    "\n",
    "# Apply ranking functions\n",
    "ranked_df = sales_df.withColumn(\n",
    "    \"row_number\", row_number().over(by_region_amount)\n",
    ").withColumn(\n",
    "    \"rank\", rank().over(by_region_amount)\n",
    ").withColumn(\n",
    "    \"dense_rank\", dense_rank().over(by_region_amount)\n",
    ").withColumn(\n",
    "    \"sales_sequence\", row_number().over(by_salesperson_date)\n",
    ")\n",
    "\n",
    "print(\"Ranking by region and amount (descending):\")\n",
    "ranked_df.select(\n",
    "    \"region\", \"salesperson\", \"amount\", \"row_number\", \"rank\", \"dense_rank\"\n",
    ").orderBy(\"region\", col(\"amount\").desc()).show()\n",
    "\n",
    "print(\"\\nSales sequence by salesperson and date:\")\n",
    "ranked_df.select(\n",
    "    \"salesperson\", \"date\", \"amount\", \"sales_sequence\"\n",
    ").orderBy(\"salesperson\", \"date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Ranking Differences\n",
    "\n",
    "```python\n",
    "# Sample data: [100, 100, 90, 80]\n",
    "# row_number(): [1, 2, 3, 4]      # Always unique\n",
    "# rank():       [1, 1, 3, 4]      # Ties get same rank, skip next\n",
    "# dense_rank(): [1, 1, 2, 3]      # Ties get same rank, no skipping\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top N Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top N analysis\n",
    "print(\"üéØ TOP N ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Top 2 salespeople by region\n",
    "top_by_region = sales_df.withColumn(\n",
    "    \"rank_in_region\", rank().over(\n",
    "        Window.partitionBy(\"region\").orderBy(col(\"amount\").desc())\n",
    "    )\n",
    ").filter(col(\"rank_in_region\") <= 2)\n",
    "\n",
    "print(\"Top 2 sales by region:\")\n",
    "top_by_region.select(\n",
    "    \"region\", \"salesperson\", \"amount\", \"rank_in_region\"\n",
    ").orderBy(\"region\", \"rank_in_region\").show()\n",
    "\n",
    "# Top performers overall\n",
    "overall_ranking = sales_df.withColumn(\n",
    "    \"overall_rank\", rank().over(\n",
    "        Window.orderBy(col(\"amount\").desc())\n",
    "    )\n",
    ").filter(col(\"overall_rank\") <= 5)\n",
    "\n",
    "print(\"\\nTop 5 sales overall:\")\n",
    "overall_ranking.select(\n",
    "    \"salesperson\", \"region\", \"category\", \"amount\", \"overall_rank\"\n",
    ").orderBy(\"overall_rank\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Running Totals and Moving Aggregates\n",
    "\n",
    "### Running Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running totals\n",
    "print(\"üìà RUNNING TOTALS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Running total by salesperson over time\n",
    "running_total_window = Window.partitionBy(\"salesperson\").orderBy(\"date\")\n",
    "\n",
    "running_df = sales_df.withColumn(\n",
    "    \"running_total\", sum(\"amount\").over(running_total_window)\n",
    ").withColumn(\n",
    "    \"running_count\", count(\"*\").over(running_total_window)\n",
    ").withColumn(\n",
    "    \"running_avg\", avg(\"amount\").over(running_total_window)\n",
    ")\n",
    "\n",
    "print(\"Running totals by salesperson:\")\n",
    "running_df.select(\n",
    "    \"salesperson\", \"date\", \"amount\", \"running_total\", \"running_count\", \"running_avg\"\n",
    ").orderBy(\"salesperson\", \"date\").show()\n",
    "\n",
    "# Cumulative percentage\n",
    "total_by_person = sales_df.groupBy(\"salesperson\").agg(sum(\"amount\").alias(\"total_amount\"))\n",
    "percent_window = Window.orderBy(col(\"total_amount\").desc())\n",
    "\n",
    "percentile_df = total_by_person.withColumn(\n",
    "    \"cumulative_amount\", sum(\"total_amount\").over(percent_window)\n",
    ").withColumn(\n",
    "    \"total_overall\", sum(\"total_amount\").over())\n",
    ").withColumn(\n",
    "    \"cumulative_percent\", col(\"cumulative_amount\") / col(\"total_overall\") * 100\n",
    ")\n",
    "\n",
    "print(\"\\nCumulative percentage of total sales:\")\n",
    "percentile_df.select(\n",
    "    \"salesperson\", \"total_amount\", \"cumulative_amount\", \"cumulative_percent\"\n",
    ").orderBy(col(\"total_amount\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Averages and Rolling Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving averages\n",
    "print(\"üìä MOVING AVERAGES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Moving average over last 3 sales per salesperson\n",
    "moving_window = Window.partitionBy(\"salesperson\").orderBy(\"date\").rowsBetween(-2, 0)\n",
    "\n",
    "moving_df = sales_df.withColumn(\n",
    "    \"moving_avg_3\", avg(\"amount\").over(moving_window)\n",
    ").withColumn(\n",
    "    \"moving_sum_3\", sum(\"amount\").over(moving_window)\n",
    ").withColumn(\n",
    "    \"moving_count\", count(\"*\").over(moving_window)\n",
    ")\n",
    "\n",
    "print(\"Moving averages (3-sale window):\")\n",
    "moving_df.select(\n",
    "    \"salesperson\", \"date\", \"amount\", \"moving_count\", \"moving_sum_3\", \"moving_avg_3\"\n",
    ").orderBy(\"salesperson\", \"date\").show()\n",
    "\n",
    "# Unbounded preceding (all previous rows)\n",
    "unbounded_window = Window.partitionBy(\"salesperson\").orderBy(\"date\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "unbounded_df = sales_df.withColumn(\n",
    "    \"cumulative_avg\", avg(\"amount\").over(unbounded_window)\n",
    ").withColumn(\n",
    "    \"cumulative_max\", max(\"amount\").over(unbounded_window)\n",
    ")\n",
    "\n",
    "print(\"\\nCumulative statistics (unbounded preceding):\")\n",
    "unbounded_df.select(\n",
    "    \"salesperson\", \"date\", \"amount\", \"cumulative_avg\", \"cumulative_max\"\n",
    ").orderBy(\"salesperson\", \"date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Lag and Lead Functions\n",
    "\n",
    "### Accessing Previous and Next Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag and Lead functions\n",
    "print(\"üîÑ LAG AND LEAD FUNCTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare current sale with previous sales\n",
    "lag_lead_df = sales_df.withColumn(\n",
    "    \"prev_sale\", lag(\"amount\", 1).over(\n",
    "        Window.partitionBy(\"salesperson\").orderBy(\"date\")\n",
    "    )\n",
    ").withColumn(\n",
    "    \"next_sale\", lead(\"amount\", 1).over(\n",
    "        Window.partitionBy(\"salesperson\").orderBy(\"date\")\n",
    "    )\n",
    ").withColumn(\n",
    "    \"sale_change\", col(\"amount\") - col(\"prev_sale\")\n",
    ").withColumn(\n",
    "    \"sale_trend\", \n",
    "        when(col(\"amount\") > col(\"prev_sale\"), \"‚Üë Increasing\")\n",
    "        .when(col(\"amount\") < col(\"prev_sale\"), \"‚Üì Decreasing\")\n",
    "        .otherwise(\"‚Üí Same\")\n",
    ")\n",
    "\n",
    "print(\"Sale comparisons with previous/next:\")\n",
    "lag_lead_df.select(\n",
    "    \"salesperson\", \"date\", \"amount\", \"prev_sale\", \"next_sale\", \"sale_change\", \"sale_trend\"\n",
    ").orderBy(\"salesperson\", \"date\").show()\n",
    "\n",
    "# Performance analysis with lag\n",
    "performance_df = sales_df.withColumn(\n",
    "    \"prev_amount\", lag(\"amount\", 1).over(\n",
    "        Window.partitionBy(\"salesperson\").orderBy(\"date\")\n",
    "    )\n",
    ").withColumn(\n",
    "    \"improvement\", \n",
    "        when(col(\"prev_amount\").isNull(), \"First Sale\")\n",
    "        .when(col(\"amount\") > col(\"prev_amount\"), \"Improved\")\n",
    "        .when(col(\"amount\") < col(\"prev_amount\"), \"Declined\")\n",
    "        .otherwise(\"Maintained\")\n",
    ")\n",
    "\n",
    "print(\"\\nPerformance analysis:\")\n",
    "performance_df.select(\n",
    "    \"salesperson\", \"date\", \"amount\", \"prev_amount\", \"improvement\"\n",
    ").orderBy(\"salesperson\", \"date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Advanced Window Specifications\n",
    "\n",
    "### Frame Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced window specifications\n",
    "print(\"üéõÔ∏è ADVANCED WINDOW SPECIFICATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Different frame types\n",
    "\n",
    "# 1. ROWS frame (physical rows)\n",
    "rows_frame = Window.partitionBy(\"region\").orderBy(\"date\").rowsBetween(-1, 1)\n",
    "\n",
    "# 2. RANGE frame (logical range)\n",
    "range_frame = Window.partitionBy(\"region\").orderBy(\"amount\").rangeBetween(-500, 500)\n",
    "\n",
    "# Apply different frames\n",
    "advanced_df = sales_df.withColumn(\n",
    "    \"rows_avg_3\", avg(\"amount\").over(rows_frame)\n",
    ").withColumn(\n",
    "    \"range_count\", count(\"*\").over(range_frame)\n",
    ")\n",
    "\n",
    "print(\"Different window frame types:\")\n",
    "print(\"ROWS frame: Physical rows around current row\")\n",
    "print(\"RANGE frame: Logical range based on ORDER BY column\\n\")\n",
    "\n",
    "advanced_df.select(\n",
    "    \"region\", \"date\", \"amount\", \"rows_avg_3\", \"range_count\"\n",
    ").orderBy(\"region\", \"date\").show()\n",
    "\n",
    "# Complex window with multiple functions\n",
    "complex_window = Window.partitionBy(\"salesperson\").orderBy(\"date\")\n",
    "\n",
    "complex_df = sales_df.withColumn(\n",
    "    \"sale_rank\", row_number().over(complex_window)\n",
    ").withColumn(\n",
    "    \"running_total\", sum(\"amount\").over(\n",
    "        complex_window.rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "    )\n",
    ").withColumn(\n",
    "    \"future_sales\", sum(\"amount\").over(\n",
    "        complex_window.rowsBetween(1, 2)\n",
    "    )\n",
    ").withColumn(\n",
    "    \"sales_trend\", \n",
    "        lag(\"amount\", 1).over(complex_window) - lag(\"amount\", 2).over(complex_window)\n",
    ")\n",
    "\n",
    "print(\"Complex multi-function windows:\")\n",
    "complex_df.select(\n",
    "    \"salesperson\", \"date\", \"amount\", \"sale_rank\", \"running_total\", \"future_sales\", \"sales_trend\"\n",
    ").orderBy(\"salesperson\", \"date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Business Analytics Examples\n",
    "\n",
    "### Customer Segmentation and RFM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business analytics\n",
    "print(\"üìä BUSINESS ANALYTICS EXAMPLES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate salesperson metrics\n",
    "salesperson_metrics = sales_df.groupBy(\"salesperson\").agg(\n",
    "    sum(\"amount\").alias(\"total_sales\"),\n",
    "    count(\"*\").alias(\"total_transactions\"),\n",
    "    avg(\"amount\").alias(\"avg_sale\"),\n",
    "    max(\"amount\").alias(\"best_sale\"),\n",
    "    countDistinct(\"category\").alias(\"categories_sold\"),\n",
    "    countDistinct(\"region\").alias(\"regions_active\")\n",
    ")\n",
    "\n",
    "# Add performance ranking\n",
    "rank_window = Window.orderBy(col(\"total_sales\").desc())\n",
    "\n",
    "performance_ranked = salesperson_metrics.withColumn(\n",
    "    \"sales_rank\", rank().over(rank_window)\n",
    ").withColumn(\n",
    "    \"sales_percentile\", F.percentile_approx(\"total_sales\", 0.5).over()\n",
    ").withColumn(\n",
    "    \"performance_tier\",\n",
    "        when(col(\"total_sales\") > col(\"sales_percentile\") * 1.5, \"Top Performer\")\n",
    "        .when(col(\"total_sales\") > col(\"sales_percentile\"), \"Good Performer\")\n",
    "        .otherwise(\"Needs Improvement\")\n",
    ")\n",
    "\n",
    "print(\"Salesperson Performance Ranking:\")\n",
    "performance_ranked.select(\n",
    "    \"sales_rank\", \"salesperson\", \"total_sales\", \"total_transactions\", \n",
    "    \"avg_sale\", \"performance_tier\"\n",
    ").orderBy(\"sales_rank\").show()\n",
    "\n",
    "# Monthly trends with window functions\n",
    "monthly_window = Window.orderBy(\"date\")\n",
    "\n",
    "monthly_analysis = sales_df.withColumn(\n",
    "    \"month\", F.date_format(\"date\", \"yyyy-MM\")\n",
    ").groupBy(\"month\").agg(\n",
    "    sum(\"amount\").alias(\"monthly_sales\"),\n",
    "    count(\"*\").alias(\"transaction_count\"),\n",
    "    countDistinct(\"salesperson\").alias(\"active_sellers\")\n",
    ").withColumn(\n",
    "    \"prev_month_sales\", lag(\"monthly_sales\", 1).over(monthly_window)\n",
    ").withColumn(\n",
    "    \"sales_growth\", \n",
    "        when(col(\"prev_month_sales\").isNotNull(), \n",
    "             (col(\"monthly_sales\") - col(\"prev_month_sales\")) / col(\"prev_month_sales\") * 100\n",
    "        ).otherwise(0)\n",
    ").orderBy(\"month\")\n",
    "\n",
    "print(\"\\nMonthly Sales Trends:\")\n",
    "monthly_analysis.select(\n",
    "    \"month\", \"monthly_sales\", \"transaction_count\", \"active_sellers\", \"sales_growth\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Performance Considerations\n",
    "\n",
    "### Optimizing Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance optimization\n",
    "print(\"‚ö° WINDOW FUNCTION PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create larger dataset for performance testing\n",
    "large_data = [\n",
    "    (f\"salesperson_{i%100}\", f\"region_{(i%5)+1}\", 100 + (i % 900), f\"2023-{(i%12)+1:02d}-{i%28+1:02d}\")\n",
    "    for i in range(10000)\n",
    "]\n",
    "\n",
    "large_df = spark.createDataFrame(large_data, \n",
    "    [\"salesperson\", \"region\", \"amount\", \"date\"]\n",
    ")\n",
    "\n",
    "print(f\"Large dataset: {large_df.count():,} records\")\n",
    "\n",
    "# Test different window strategies\n",
    "import time\n",
    "\n",
    "# Strategy 1: Multiple separate window operations\n",
    "start_time = time.time()\n",
    "window1 = Window.partitionBy(\"salesperson\").orderBy(\"date\")\n",
    "\n",
    "result1 = large_df.withColumn(\"rank\", rank().over(window1)) \\\n",
    "    .withColumn(\"running_total\", sum(\"amount\").over(window1)) \\\n",
    "    .filter(col(\"rank\") <= 3)\n",
    "\n",
    "strategy1_time = time.time() - start_time\n",
    "print(f\"Strategy 1 (multiple windows): {strategy1_time:.3f} seconds\")\n",
    "\n",
    "# Strategy 2: Pre-filter then window\n",
    "start_time = time.time()\n",
    "filtered_df = large_df.filter(col(\"amount\") > 500)  # Reduce data first\n",
    "window2 = Window.partitionBy(\"salesperson\").orderBy(\"date\")\n",
    "\n",
    "result2 = filtered_df.withColumn(\"rank\", rank().over(window2)) \\\n",
    "    .withColumn(\"running_total\", sum(\"amount\").over(window2)) \\\n",
    "    .filter(col(\"rank\") <= 3)\n",
    "\n",
    "strategy2_time = time.time() - start_time\n",
    "print(f\"Strategy 2 (pre-filter): {strategy2_time:.3f} seconds\")\n",
    "\n",
    "print(f\"\\nPre-filtering improved performance by {strategy1_time/strategy2_time:.1f}x\")\n",
    "\n",
    "# Best practices summary\n",
    "print(\"\\nüöÄ WINDOW FUNCTION BEST PRACTICES:\")\n",
    "print(\"1. Filter data before applying windows\")\n",
    "print(\"2. Use appropriate partition keys\")\n",
    "print(\"3. Minimize window frame sizes\")\n",
    "print(\"4. Cache intermediate results if reused\")\n",
    "print(\"5. Consider approximate functions for large data\")\n",
    "print(\"6. Monitor Spark UI for window operation performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö® Common Mistakes and Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common mistakes\n",
    "print(\"üö® COMMON WINDOW FUNCTION MISTAKES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Mistake 1: Forgetting ORDER BY in ranking functions\n",
    "print(\"‚ùå Mistake: No ORDER BY in ranking\")\n",
    "bad_rank = sales_df.withColumn(\"bad_rank\", rank().over(Window.partitionBy(\"region\")))\n",
    "print(\"Rank without ORDER BY (unpredictable results):\")\n",
    "bad_rank.select(\"region\", \"amount\", \"bad_rank\").show(5)\n",
    "\n",
    "print(\"\\n‚úÖ Correct: Include ORDER BY\")\n",
    "good_rank = sales_df.withColumn(\"good_rank\", rank().over(\n",
    "    Window.partitionBy(\"region\").orderBy(col(\"amount\").desc())\n",
    "))\n",
    "print(\"Rank with ORDER BY (correct results):\")\n",
    "good_rank.select(\"region\", \"amount\", \"good_rank\").show(5)\n",
    "\n",
    "# Mistake 2: Using wrong frame type\n",
    "print(\"\\n‚ùå Mistake: Using ROWS when RANGE is needed\")\n",
    "rows_frame = Window.partitionBy(\"region\").orderBy(\"amount\").rowsBetween(-2, 2)\n",
    "range_frame = Window.partitionBy(\"region\").orderBy(\"amount\").rangeBetween(-200, 200)\n",
    "\n",
    "rows_result = sales_df.withColumn(\"rows_neighbors\", F.collect_list(\"amount\").over(rows_frame))\n",
    "range_result = sales_df.withColumn(\"range_neighbors\", F.collect_list(\"amount\").over(range_frame))\n",
    "\n",
    "print(\"ROWS frame (physical neighbors):\")\n",
    "rows_result.select(\"region\", \"amount\", \"rows_neighbors\").show(3, truncate=False)\n",
    "\n",
    "print(\"RANGE frame (logical range):\")\n",
    "range_result.select(\"region\", \"amount\", \"range_neighbors\").show(3, truncate=False)\n",
    "\n",
    "# Mistake 3: Not handling nulls in ORDER BY\n",
    "print(\"\\n‚ùå Mistake: Nulls in ORDER BY column\")\n",
    "null_data = [(\"Alice\", 100), (\"Bob\", None), (\"Charlie\", 200)]\n",
    "null_df = spark.createDataFrame(null_data, [\"name\", \"score\"])\n",
    "\n",
    "null_rank = null_df.withColumn(\"rank\", rank().over(Window.orderBy(\"score\")))\n",
    "print(\"Rank with nulls (nulls first by default):\")\n",
    "null_rank.show()\n",
    "\n",
    "print(\"\\n‚úÖ Solution: Handle nulls explicitly\")\n",
    "null_handled = null_df.withColumn(\"rank\", rank().over(\n",
    "    Window.orderBy(F.coalesce(\"score\", -999))  # Nulls become -999\n",
    "))\n",
    "null_handled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways\n",
    "\n",
    "### What You Learned:\n",
    "- ‚úÖ **`Window.partitionBy().orderBy()`** - Define window specifications\n",
    "- ‚úÖ **`row_number()`, `rank()`, `dense_rank()`** - Ranking functions\n",
    "- ‚úÖ **`lag()`, `lead()`** - Access previous/next rows\n",
    "- ‚úÖ **Running totals and moving averages** - Aggregate over windows\n",
    "- ‚úÖ **Frame specifications** - ROWS vs RANGE frames\n",
    "- ‚úÖ **Performance optimization** - Efficient window operations\n",
    "\n",
    "### Window Function Types:\n",
    "- üî∏ **Ranking**: `row_number()`, `rank()`, `dense_rank()`, `percent_rank()`\n",
    "- üî∏ **Aggregate**: `sum()`, `avg()`, `min()`, `max()`, `count()` over windows\n",
    "- üî∏ **Navigation**: `lag()`, `lead()`, `first()`, `last()`\n",
    "- üî∏ **Distribution**: `cume_dist()`, `percentile_approx()`\n",
    "\n",
    "### Frame Types:\n",
    "- üî∏ **ROWS**: Physical row positions (`rowsBetween(-1, 1)`)\n",
    "- üî∏ **RANGE**: Logical value ranges (`rangeBetween(-100, 100)`)\n",
    "- üî∏ **UNBOUNDED**: All rows (`unboundedPreceding` to `unboundedFollowing`)\n",
    "\n",
    "### Performance Best Practices:\n",
    "- üî∏ **Filter before windowing** to reduce data volume\n",
    "- üî∏ **Choose narrow partitions** for better parallelism\n",
    "- üî∏ **Use appropriate frame sizes** (smaller = faster)\n",
    "- üî∏ **Cache windowed results** if reused multiple times\n",
    "- üî∏ **Monitor shuffle operations** in Spark UI\n",
    "\n",
    "### Common Patterns:\n",
    "- üî∏ `Window.partitionBy(\"group\").orderBy(\"sort_col\")` - Basic window spec\n",
    "- üî∏ `.rowsBetween(Window.unboundedPreceding, Window.currentRow)` - Running totals\n",
    "- üî∏ `.rowsBetween(-N, N)` - Moving averages\n",
    "- üî∏ `lag(\"col\", offset)` - Compare with previous rows\n",
    "- üî∏ `rank().over(window)` - Top N analysis\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you master window functions, you're ready for:\n",
    "\n",
    "1. **DataFrame Joins** - Combining multiple DataFrames\n",
    "2. **Complex Data Types** - Arrays, maps, and structs\n",
    "3. **Spark SQL Integration** - SQL interface for DataFrames\n",
    "4. **Advanced Analytics** - Time series and predictive modeling\n",
    "\n",
    "**Window functions enable sophisticated analytical queries!**\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations! You now wield the analytical power of window functions like a data science expert!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
