{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Classification Basics: Predictive Modeling with Spark MLlib\n",
    "\n",
    "**Time to complete:** 45 minutes  \n",
    "**Difficulty:** Intermediate  \n",
    "**Prerequisites:** DataFrames, statistics basics, ML concepts\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will master:\n",
    "- ‚úÖ **Classification fundamentals** - Binary vs multiclass\n",
    "- ‚úÖ **Logistic regression** - Probability-based classification\n",
    "- ‚úÖ **Decision trees** - Tree-based classification\n",
    "- ‚úÖ **Random forests** - Ensemble classification\n",
    "- ‚úÖ **Model evaluation** - Accuracy, precision, recall, F1-score\n",
    "- ‚úÖ **Feature engineering** - Preparing data for ML\n",
    "- ‚úÖ **Pipeline construction** - End-to-end ML workflows\n",
    "\n",
    "**Spark MLlib makes distributed machine learning accessible!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Understanding Classification\n",
    "\n",
    "### What is Classification?\n",
    "\n",
    "**Classification** is a supervised learning technique that predicts categorical labels for input data.\n",
    "\n",
    "```\n",
    "Input Features:     [age, income, education, credit_score]\n",
    "Prediction Task:    Will this customer default on loan?\n",
    "Output:            \"Yes\" (will default) or \"No\" (won't default)\n",
    "```\n",
    "\n",
    "### Types of Classification\n",
    "\n",
    "1. **Binary Classification**: Two classes (Yes/No, True/False)\n",
    "2. **Multiclass Classification**: Three or more classes (cat/dog/bird)\n",
    "3. **Multilabel Classification**: Multiple labels per instance\n",
    "\n",
    "**We'll focus on binary and multiclass classification in this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Classification Examples\n",
    "\n",
    "- **Fraud Detection**: Transaction ‚Üí Fraudulent/legitimate\n",
    "- **Spam Filtering**: Email ‚Üí Spam/not spam\n",
    "- **Medical Diagnosis**: Symptoms ‚Üí Disease classification\n",
    "- **Credit Scoring**: Application ‚Üí Approve/deny\n",
    "- **Image Recognition**: Pixels ‚Üí Object categories\n",
    "- **Sentiment Analysis**: Text ‚Üí Positive/negative/neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLlib_Classification_Basics\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"‚úÖ Spark ready - Version: {spark.version}\")\n",
    "print(\"MLlib classification libraries imported\")\n",
    "\n",
    "# Enable MLlib optimizations\n",
    "spark.conf.set(\"spark.ml.optimizer.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.ml.decisionTree.maxBins\", \"32\")\n",
    "spark.conf.set(\"spark.ml.decisionTree.maxDepth\", \"10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Preparing Classification Data\n",
    "\n",
    "### Sample Dataset: Customer Churn Prediction\n",
    "\n",
    "**We'll predict whether customers will churn (cancel their subscription) based on their usage patterns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample customer churn dataset\n",
    "print(\"üìä CREATING SAMPLE DATASET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate synthetic customer data\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "customer_data = []\n",
    "for i in range(10000):\n",
    "    # Customer features\n",
    "    age = random.randint(18, 80)\n",
    "    monthly_charges = round(random.uniform(20, 200), 2)\n",
    "    tenure_months = random.randint(1, 72)\n",
    "    total_charges = round(monthly_charges * tenure_months * random.uniform(0.8, 1.2), 2)\n",
    "    \n",
    "    # Categorical features\n",
    "    gender = random.choice([\"Male\", \"Female\"])\n",
    "    contract_type = random.choice([\"Month-to-month\", \"One year\", \"Two year\"])\n",
    "    internet_service = random.choice([\"DSL\", \"Fiber optic\", \"No\"])\n",
    "    \n",
    "    # Derived features\n",
    "    avg_monthly_usage = random.randint(0, 1000)\n",
    "    support_calls = random.randint(0, 10)\n",
    "    \n",
    "    # Churn probability (simplified logic)\n",
    "    churn_risk = (\n",
    "        (monthly_charges > 100) * 0.3 +\n",
    "        (tenure_months < 12) * 0.4 +\n",
    "        (contract_type == \"Month-to-month\") * 0.3 +\n",
    "        (support_calls > 3) * 0.2 +\n",
    "        random.uniform(0, 0.5)\n",
    "    )\n",
    "    \n",
    "    churn = 1 if churn_risk > 0.7 else 0\n",
    "    \n",
    "    customer_data.append({\n",
    "        \"customer_id\": f\"CUST_{i:04d}\",\n",
    "        \"age\": age,\n",
    "        \"gender\": gender,\n",
    "        \"monthly_charges\": monthly_charges,\n",
    "        \"tenure_months\": tenure_months,\n",
    "        \"total_charges\": total_charges,\n",
    "        \"contract_type\": contract_type,\n",
    "        \"internet_service\": internet_service,\n",
    "        \"avg_monthly_usage\": avg_monthly_usage,\n",
    "        \"support_calls\": support_calls,\n",
    "        \"churn\": churn\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "churn_df = spark.createDataFrame(customer_data)\n",
    "\n",
    "print(\"Customer churn dataset created:\")\n",
    "print(f\"Total customers: {churn_df.count():,}\")\n",
    "print(f\"Churn rate: {churn_df.filter('churn = 1').count() / churn_df.count():.1%}\")\n",
    "\n",
    "print(\"\\nDataset schema:\")\n",
    "churn_df.printSchema()\n",
    "\n",
    "print(\"\\nSample data:\")\n",
    "churn_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "**Understanding your data is crucial before building ML models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "print(\"üîç DATA EXPLORATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Target variable distribution:\")\n",
    "churn_df.groupBy(\"churn\").count().show()\n",
    "\n",
    "# Numeric feature statistics\n",
    "numeric_cols = [\"age\", \"monthly_charges\", \"tenure_months\", \"total_charges\", \"avg_monthly_usage\", \"support_calls\"]\n",
    "print(\"\\nNumeric feature statistics:\")\n",
    "churn_df.select(numeric_cols).summary().show()\n",
    "\n",
    "# Categorical feature distributions\n",
    "categorical_cols = [\"gender\", \"contract_type\", \"internet_service\"]\n",
    "print(\"\\nCategorical feature distributions:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    churn_df.groupBy(col).count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# Churn analysis by categories\n",
    "print(\"\\nChurn rate by contract type:\")\n",
    "churn_df.groupBy(\"contract_type\").agg(\n",
    "    F.count(\"*\").alias(\"total\"),\n",
    "    F.sum(\"churn\").alias(\"churned\"),\n",
    "    (F.sum(\"churn\") / F.count(\"*\") * 100).alias(\"churn_rate_%\")\n",
    ").show()\n",
    "\n",
    "print(\"\\nChurn rate by internet service:\")\n",
    "churn_df.groupBy(\"internet_service\").agg(\n",
    "    F.count(\"*\").alias(\"total\"),\n",
    "    F.sum(\"churn\").alias(\"churned\"),\n",
    "    (F.sum(\"churn\") / F.count(\"*\") * 100).alias(\"churn_rate_%\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Feature Engineering for Classification\n",
    "\n",
    "### Preparing Features for ML Models\n",
    "\n",
    "**ML algorithms require numerical features. We need to transform categorical variables and prepare the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering pipeline\n",
    "print(\"üîß FEATURE ENGINEERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. String indexing for categorical variables\n",
    "gender_indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_index\")\n",
    "contract_indexer = StringIndexer(inputCol=\"contract_type\", outputCol=\"contract_index\")\n",
    "internet_indexer = StringIndexer(inputCol=\"internet_service\", outputCol=\"internet_index\")\n",
    "\n",
    "# 2. One-hot encoding for categorical variables\n",
    "gender_encoder = OneHotEncoder(inputCol=\"gender_index\", outputCol=\"gender_vec\")\n",
    "contract_encoder = OneHotEncoder(inputCol=\"contract_index\", outputCol=\"contract_vec\")\n",
    "internet_encoder = OneHotEncoder(inputCol=\"internet_index\", outputCol=\"internet_vec\")\n",
    "\n",
    "# 3. Assemble all features into a single vector\n",
    "feature_cols = [\n",
    "    \"age\", \"monthly_charges\", \"tenure_months\", \"total_charges\",\n",
    "    \"avg_monthly_usage\", \"support_calls\",\n",
    "    \"gender_vec\", \"contract_vec\", \"internet_vec\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(stages=[\n",
    "    gender_indexer, contract_indexer, internet_indexer,\n",
    "    gender_encoder, contract_encoder, internet_encoder,\n",
    "    assembler\n",
    "])\n",
    "\n",
    "# Fit and transform the data\n",
    "preprocessing_model = preprocessing_pipeline.fit(churn_df)\n",
    "processed_df = preprocessing_model.transform(churn_df)\n",
    "\n",
    "print(\"Feature engineering completed\")\n",
    "print(\"\\nProcessed data sample:\")\n",
    "processed_df.select(\"customer_id\", \"features\", \"churn\").show(5, truncate=False)\n",
    "\n",
    "# Check feature vector size\n",
    "print(f\"\\nFeature vector size: {len(feature_cols)} features\")\n",
    "print(\"(Including one-hot encoded categorical variables)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "**Split data into training and testing sets for model evaluation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "print(\"üéØ TRAIN/TEST SPLIT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Split the processed data\n",
    "train_df, test_df = processed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training set: {train_df.count():,} samples\")\n",
    "print(f\"Testing set: {test_df.count():,} samples\")\n",
    "print(f\"Split ratio: {train_df.count()/processed_df.count():.1%} train, {test_df.count()/processed_df.count():.1%} test\")\n",
    "\n",
    "# Check class distribution in splits\n",
    "print(\"\\nClass distribution:\")\n",
    "print(\"Training set:\")\n",
    "train_df.groupBy(\"churn\").count().show()\n",
    "print(\"Testing set:\")\n",
    "test_df.groupBy(\"churn\").count().show()\n",
    "\n",
    "# Check for data quality\n",
    "print(\"\\nData quality checks:\")\n",
    "print(f\"Training null features: {train_df.filter('features is null').count()}\")\n",
    "print(f\"Testing null features: {test_df.filter('features is null').count()}\")\n",
    "print(f\"Training null labels: {train_df.filter('churn is null').count()}\")\n",
    "print(f\"Testing null labels: {test_df.filter('churn is null').count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Logistic Regression: Probability-Based Classification\n",
    "\n",
    "### Understanding Logistic Regression\n",
    "\n",
    "**Logistic regression** predicts the probability of a binary outcome using a logistic (sigmoid) function.\n",
    "\n",
    "```\n",
    "Linear Combination: z = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b\n",
    "Probability: p = 1 / (1 + e^(-z))\n",
    "Prediction: class = 1 if p > 0.5, else 0\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- Interpretable coefficients\n",
    "- Probabilistic outputs\n",
    "- Fast training and prediction\n",
    "- Works well with linear relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "print(\"üìà LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create and train logistic regression model\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"churn\",\n",
    "    maxIter=100,\n",
    "    regParam=0.01,  # L2 regularization\n",
    "    elasticNetParam=0.0,  # L2 only\n",
    "    family=\"binomial\"  # Binary classification\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Logistic Regression model...\")\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "print(\"‚úÖ Model trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.transform(test_df)\n",
    "\n",
    "print(\"\\nPredictions sample:\")\n",
    "lr_predictions.select(\"customer_id\", \"churn\", \"prediction\", \"probability\").show(10)\n",
    "\n",
    "# Model coefficients and intercept\n",
    "print(f\"\\nModel coefficients shape: {lr_model.coefficients.size}\")\n",
    "print(f\"Model intercept: {lr_model.intercept:.4f}\")\n",
    "\n",
    "# Feature importance (absolute coefficients)\n",
    "feature_importance = list(zip(feature_cols, lr_model.coefficients.toArray()))\n",
    "feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "for feature, coef in feature_importance[:5]:\n",
    "    print(f\"  {feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå≥ Decision Trees: Rule-Based Classification\n",
    "\n",
    "### Understanding Decision Trees\n",
    "\n",
    "**Decision trees** recursively split data based on feature values to create classification rules.\n",
    "\n",
    "```\n",
    "Root Node\n",
    "‚îú‚îÄ‚îÄ Feature A > threshold?\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Yes ‚Üí Class 1\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ No ‚Üí Feature B > threshold?\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ Yes ‚Üí Class 0\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ No ‚Üí Class 1\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- Easy to interpret and visualize\n",
    "- Handles both numerical and categorical features\n",
    "- No need for feature scaling\n",
    "- Can capture non-linear relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree model\n",
    "print(\"üå≥ DECISION TREE CLASSIFIER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create and train decision tree model\n",
    "dt = DecisionTreeClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"churn\",\n",
    "    maxDepth=5,  # Limit tree depth to prevent overfitting\n",
    "    maxBins=32,  # Number of bins for continuous features\n",
    "    impurity=\"gini\",  # Split quality measure\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Decision Tree model...\")\n",
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "print(\"‚úÖ Decision Tree trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "\n",
    "print(\"\\nPredictions sample:\")\n",
    "dt_predictions.select(\"customer_id\", \"churn\", \"prediction\").show(10)\n",
    "\n",
    "# Tree information\n",
    "print(f\"\\nTree depth: {dt_model.depth}\")\n",
    "print(f\"Number of nodes: {dt_model.numNodes}\")\n",
    "print(f\"Feature importances shape: {dt_model.featureImportances.size}\")\n",
    "\n",
    "# Feature importances\n",
    "feature_importance_dt = list(zip(feature_cols, dt_model.featureImportances.toArray()))\n",
    "feature_importance_dt.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "for feature, importance in feature_importance_dt[:5]:\n",
    "    print(f\"  {feature}: {importance:.4f}\")\n",
    "\n",
    "# Print tree structure (simplified)\n",
    "print(\"\\nDecision tree structure preview:\")\n",
    "print(dt_model.toDebugString[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå≤ Random Forest: Ensemble Classification\n",
    "\n",
    "### Understanding Random Forests\n",
    "\n",
    "**Random forests** combine multiple decision trees to improve accuracy and reduce overfitting.\n",
    "\n",
    "```\n",
    "Training Process:\n",
    "1. Create multiple decision trees\n",
    "2. Each tree trained on random subset of data\n",
    "3. Each tree uses random subset of features\n",
    "4. Final prediction = majority vote of all trees\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- High accuracy\n",
    "- Reduced overfitting\n",
    "- Feature importance estimation\n",
    "- Handles missing values well\n",
    "- Parallel training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest model\n",
    "print(\"üå≤ RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create and train random forest model\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"churn\",\n",
    "    numTrees=50,  # Number of trees in the forest\n",
    "    maxDepth=6,   # Maximum depth of each tree\n",
    "    maxBins=32,  # Number of bins for continuous features\n",
    "    minInstancesPerNode=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "print(\"‚úÖ Random Forest trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.transform(test_df)\n",
    "\n",
    "print(\"\\nPredictions sample:\")\n",
    "rf_predictions.select(\"customer_id\", \"churn\", \"prediction\").show(10)\n",
    "\n",
    "# Forest information\n",
    "print(f\"\\nNumber of trees: {rf_model.getNumTrees}\")\n",
    "print(f\"Total number of nodes: {rf_model.totalNumNodes}\")\n",
    "\n",
    "# Feature importances\n",
    "feature_importance_rf = list(zip(feature_cols, rf_model.featureImportances.toArray()))\n",
    "feature_importance_rf.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "for feature, importance in feature_importance_rf[:5]:\n",
    "    print(f\"  {feature}: {importance:.4f}\")\n",
    "\n",
    "# Individual tree information\n",
    "print(\"\\nForest composition:\")\n",
    "tree_info = rf_model.treeWeights  # Weights of each tree\n",
    "print(f\"All trees have equal weight: {len(set(tree_info)) == 1}\")\n",
    "print(f\"Average tree weight: {sum(tree_info)/len(tree_info):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Model Evaluation and Comparison\n",
    "\n",
    "### Classification Metrics\n",
    "\n",
    "**Evaluating classification models requires multiple metrics beyond accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "print(\"üìä MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create evaluators\n",
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"churn\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "multiclass_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"churn\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Evaluate all models\n",
    "models = {\n",
    "    \"Logistic Regression\": lr_predictions,\n",
    "    \"Decision Tree\": dt_predictions,\n",
    "    \"Random Forest\": rf_predictions\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, predictions in models.items():\n",
    "    print(f\"\\nüîç Evaluating {model_name}:\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    confusion_matrix = predictions.groupBy(\"churn\", \"prediction\").count()\n",
    "    print(\"Confusion Matrix:\")\n",
    "    confusion_matrix.show()\n",
    "    \n",
    "    # Calculate metrics manually for clarity\n",
    "    metrics = predictions.select(\"churn\", \"prediction\").groupBy().agg(\n",
    "        # Accuracy\n",
    "        (F.sum(F.when(F.col(\"churn\") == F.col(\"prediction\"), 1).otherwise(0)) / F.count(\"*\")).alias(\"accuracy\"),\n",
    "        \n",
    "        # Precision for class 1 (churn)\n",
    "        (F.sum(F.when((F.col(\"prediction\") == 1) & (F.col(\"churn\") == 1), 1).otherwise(0)) /\n",
    "         F.sum(F.when(F.col(\"prediction\") == 1, 1).otherwise(0))).alias(\"precision\"),\n",
    "        \n",
    "        # Recall for class 1 (churn)\n",
    "        (F.sum(F.when((F.col(\"prediction\") == 1) & (F.col(\"churn\") == 1), 1).otherwise(0)) /\n",
    "         F.sum(F.when(F.col(\"churn\") == 1, 1).otherwise(0))).alias(\"recall\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    # AUC using evaluator\n",
    "    auc = binary_evaluator.evaluate(predictions)\n",
    "    \n",
    "    # F1 Score using evaluator\n",
    "    f1 = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: \"f1\"})\n",
    "    \n",
    "    results[model_name] = {\n",
    "        \"accuracy\": metrics.accuracy,\n",
    "        \"precision\": metrics.precision,\n",
    "        \"recall\": metrics.recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"auc\": auc\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {metrics.accuracy:.4f}\")\n",
    "    print(f\"  Precision: {metrics.precision:.4f}\")\n",
    "    print(f\"  Recall: {metrics.recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  AUC: {auc:.4f}\")\n",
    "\n",
    "# Model comparison\n",
    "print(\"\\nüèÜ MODEL COMPARISON:\")\n",
    "print(\"Metric\" + \"\\t\" + \"\\t\".join(f\"{model[:8]:<8}\" for model in results.keys()))\n",
    "print(\"-\" * 60)\n",
    "\n",
    "metrics_to_show = [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"auc\"]\n",
    "for metric in metrics_to_show:\n",
    "    values = [f\"{results[model][metric]:.4f}\" for model in results.keys()]\n",
    "    print(f\"{metric.capitalize()}\\t\" + \"\\t\".join(values))\n",
    "\n",
    "# Find best model for each metric\n",
    "print(\"\\nüèÖ BEST MODELS:\")\n",
    "for metric in metrics_to_show:\n",
    "    best_model = max(results.keys(), key=lambda m: results[m][metric])\n",
    "    best_value = results[best_model][metric]\n",
    "    print(f\"  {metric.capitalize()}: {best_model} ({best_value:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Building Complete ML Pipelines\n",
    "\n",
    "### End-to-End Classification Pipeline\n",
    "\n",
    "**Pipelines combine preprocessing, feature engineering, and model training into a single workflow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete ML pipeline\n",
    "print(\"üîß COMPLETE ML PIPELINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a complete pipeline with preprocessing + model\n",
    "complete_pipeline = Pipeline(stages=[\n",
    "    # Preprocessing stages\n",
    "    gender_indexer,\n",
    "    contract_indexer, \n",
    "    internet_indexer,\n",
    "    gender_encoder,\n",
    "    contract_encoder,\n",
    "    internet_encoder,\n",
    "    assembler,\n",
    "    \n",
    "    # Model stage\n",
    "    RandomForestClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"churn\",\n",
    "        numTrees=30,\n",
    "        maxDepth=5,\n",
    "        seed=42\n",
    "    )\n",
    "])\n",
    "\n",
    "# Train the complete pipeline\n",
    "print(\"Training complete pipeline...\")\n",
    "pipeline_model = complete_pipeline.fit(churn_df)  # Note: training on full dataset for demo\n",
    "\n",
    "print(\"‚úÖ Pipeline trained successfully\")\n",
    "\n",
    "# Make predictions with the pipeline\n",
    "pipeline_predictions = pipeline_model.transform(churn_df)\n",
    "\n",
    "print(\"\\nPipeline predictions sample:\")\n",
    "pipeline_predictions.select(\"customer_id\", \"churn\", \"prediction\").show(10)\n",
    "\n",
    "# Pipeline stages\n",
    "print(f\"\\nPipeline has {len(pipeline_model.stages)} stages:\")\n",
    "for i, stage in enumerate(pipeline_model.stages):\n",
    "    stage_name = stage.__class__.__name__\n",
    "    if hasattr(stage, \"getNumTrees\"):\n",
    "        stage_name += f\" ({stage.getNumTrees} trees)\"\n",
    "    print(f\"  Stage {i+1}: {stage_name}\")\n",
    "\n",
    "# Evaluate pipeline performance\n",
    "pipeline_auc = binary_evaluator.evaluate(pipeline_predictions)\n",
    "pipeline_f1 = multiclass_evaluator.evaluate(pipeline_predictions, {multiclass_evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"\\nPipeline Performance:\")\n",
    "print(f\"  AUC: {pipeline_auc:.4f}\")\n",
    "print(f\"  F1 Score: {pipeline_f1:.4f}\")\n",
    "\n",
    "# Save the pipeline\n",
    "pipeline_path = \"/tmp/churn_prediction_pipeline\"\n",
    "pipeline_model.write().overwrite().save(pipeline_path)\n",
    "print(f\"\\nPipeline saved to: {pipeline_path}\")\n",
    "\n",
    "# Load the pipeline (demonstration)\n",
    "# loaded_pipeline = PipelineModel.load(pipeline_path)\n",
    "# loaded_predictions = loaded_pipeline.transform(new_data)\n",
    "print(\"Pipeline can be loaded and used for new predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Hyperparameter Tuning\n",
    "\n",
    "### Optimizing Model Parameters\n",
    "\n",
    "**Hyperparameter tuning** finds the best model configuration through systematic search.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "print(\"‚öôÔ∏è HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create parameter grid for Random Forest\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20, 30]) \\\n",
    "    .addGrid(rf.maxDepth, [3, 5, 7]) \\\n",
    "    .build()\n",
    "\n",
    "print(f\"Parameter grid size: {len(param_grid)} combinations\")\n",
    "print(\"\\nParameter combinations:\")\n",
    "for i, params in enumerate(param_grid):\n",
    "    num_trees = params[rf.numTrees]\n",
    "    max_depth = params[rf.maxDepth]\n",
    "    print(f\"  {i+1}. numTrees={num_trees}, maxDepth={max_depth}\")\n",
    "\n",
    "# Create cross-validator\n",
    "cross_validator = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=binary_evaluator,\n",
    "    numFolds=3,  # 3-fold cross-validation\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Note: Full cross-validation can be slow, so we'll demonstrate with smaller data\n",
    "# In production, use a representative sample for tuning\n",
    "tuning_sample = train_df.sample(0.3, seed=42)  # 30% sample for faster tuning\n",
    "\n",
    "print(f\"\\nTuning on sample: {tuning_sample.count()} records\")\n",
    "\n",
    "# Perform cross-validation (this may take a few minutes)\n",
    "print(\"Performing cross-validation...\")\n",
    "cv_model = cross_validator.fit(tuning_sample)\n",
    "\n",
    "print(\"‚úÖ Cross-validation completed\")\n",
    "\n",
    "# Best model parameters\n",
    "best_rf_model = cv_model.bestModel\n",
    "best_params = cv_model.getEstimatorParamMaps()[cv_model.avgMetrics.index(max(cv_model.avgMetrics))]\n",
    "\n",
    "print(f\"\\nBest parameters found:\")\n",
    "print(f\"  numTrees: {best_params[rf.numTrees]}\")\n",
    "print(f\"  maxDepth: {best_params[rf.maxDepth]}\")\n",
    "print(f\"  Best AUC: {max(cv_model.avgMetrics):.4f}\")\n",
    "\n",
    "# Evaluate best model on full test set\n",
    "tuned_predictions = best_rf_model.transform(test_df)\n",
    "tuned_auc = binary_evaluator.evaluate(tuned_predictions)\n",
    "tuned_f1 = multiclass_evaluator.evaluate(tuned_predictions, {multiclass_evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"\\nTuned model performance on full test set:\")\n",
    "print(f\"  AUC: {tuned_auc:.4f}\")\n",
    "print(f\"  F1 Score: {tuned_f1:.4f}\")\n",
    "\n",
    "# Compare with default model\n",
    "default_auc = binary_evaluator.evaluate(rf_predictions)\n",
    "improvement = (tuned_auc - default_auc) / default_auc * 100\n",
    "\n",
    "print(f\"\\nImprovement over default: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Production Deployment Considerations\n",
    "\n",
    "### Making Models Production-Ready\n",
    "\n",
    "**Production ML systems require reliability, monitoring, and maintainability.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production considerations\n",
    "print(\"üéØ PRODUCTION DEPLOYMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Model serialization and versioning\n",
    "print(\"1. MODEL SERIALIZATION & VERSIONING\")\n",
    "model_version = \"1.0.0\"\n",
    "model_path = f\"/tmp/churn_model_v{model_version}\"\n",
    "\n",
    "# Save the best model\n",
    "best_rf_model.write().overwrite().save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save preprocessing pipeline separately\n",
    "preprocessing_path = f\"/tmp/churn_preprocessing_v{model_version}\"\n",
    "preprocessing_model.write().overwrite().save(preprocessing_path)\n",
    "print(f\"Preprocessing pipeline saved to: {preprocessing_path}\")\n",
    "\n",
    "# 2. Model metadata\n",
    "print(\"\\n2. MODEL METADATA\")\n",
    "model_metadata = {\n",
    "    \"model_type\": \"RandomForestClassifier\",\n",
    "    \"version\": model_version,\n",
    "    \"training_date\": \"2024-01-15\",\n",
    "    \"features\": feature_cols,\n",
    "    \"target\": \"churn\",\n",
    "    \"metrics\": {\n",
    "        \"auc\": tuned_auc,\n",
    "        \"f1_score\": tuned_f1,\n",
    "        \"accuracy\": multiclass_evaluator.evaluate(tuned_predictions, {multiclass_evaluator.metricName: \"accuracy\"})\n",
    "    },\n",
    "    \"hyperparameters\": {\n",
    "        \"numTrees\": best_params[rf.numTrees],\n",
    "        \"maxDepth\": best_params[rf.maxDepth],\n",
    "        \"maxBins\": 32\n",
    "    },\n",
    "    \"data_info\": {\n",
    "        \"training_samples\": train_df.count(),\n",
    "        \"test_samples\": test_df.count(),\n",
    "        \"feature_count\": len(feature_cols)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save metadata (in production, use a proper metadata store)\n",
    "import json\n",
    "metadata_path = f\"/tmp/churn_model_metadata_v{model_version}.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Model metadata saved to: {metadata_path}\")\n",
    "\n",
    "# 3. Prediction function for production use\n",
    "print(\"\\n3. PRODUCTION PREDICTION FUNCTION\")\n",
    "\n",
    "def predict_churn(customer_data):\n",
    "    \"\"\"\n",
    "    Production prediction function for customer churn\n",
    "    \n",
    "    Args:\n",
    "        customer_data: DataFrame with customer features\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with churn predictions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load models (in production, load once at startup)\n",
    "        from pyspark.ml.classification import RandomForestClassificationModel\n",
    "        model = RandomForestClassificationModel.load(model_path)\n",
    "        \n",
    "        # Load preprocessing pipeline\n",
    "        from pyspark.ml import PipelineModel\n",
    "        preprocessing = PipelineModel.load(preprocessing_path)\n",
    "        \n",
    "        # Process and predict\n",
    "        processed_data = preprocessing.transform(customer_data)\n",
    "        predictions = model.transform(processed_data)\n",
    "        \n",
    "        # Return relevant columns\n",
    "        result = predictions.select(\n",
    "            \"customer_id\",\n",
    "            \"prediction\",\n",
    "            \"probability\"\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test production function\n",
    "test_customers = churn_df.limit(5)\n",
    "print(\"\\nTesting production prediction function:\")\n",
    "# predictions = predict_churn(test_customers)  # Would work with saved models\n",
    "print(\"Production function ready for deployment\")\n",
    "\n",
    "# 4. Monitoring and alerting\n",
    "print(\"\\n4. MONITORING & ALERTING\")\n",
    "monitoring_guidelines = [\n",
    "    \"Monitor prediction latency and throughput\",\n",
    "    \"Track model performance drift over time\",\n",
    "    \"Set up alerts for prediction failures\",\n",
    "    \"Log feature distributions for drift detection\",\n",
    "    \"Implement A/B testing for model updates\",\n",
    "    \"Regular model retraining schedule\"\n",
    "]\n",
    "\n",
    "print(\"Production monitoring guidelines:\")\n",
    "for guideline in monitoring_guidelines:\n",
    "    print(f\"  ‚úì {guideline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways\n",
    "\n",
    "### Classification Concepts Mastered:\n",
    "\n",
    "1. **Binary Classification**: Predicting churn (yes/no)\n",
    "2. **Feature Engineering**: Categorical encoding, feature assembly\n",
    "3. **Model Algorithms**: Logistic regression, decision trees, random forests\n",
    "4. **Model Evaluation**: Accuracy, precision, recall, F1, AUC\n",
    "5. **ML Pipelines**: End-to-end preprocessing + modeling\n",
    "6. **Hyperparameter Tuning**: Cross-validation, parameter search\n",
    "7. **Production Deployment**: Model serialization, monitoring, versioning\n",
    "\n",
    "### Model Performance Comparison:\n",
    "\n",
    "| Algorithm | Strengths | Weaknesses | Use Case |\n",
    "|-----------|-----------|------------|----------|\n",
    "| **Logistic Regression** | Interpretable, fast, probabilistic | Assumes linear relationships | Baseline, interpretable models |\n",
    "| **Decision Trees** | Interpretable, handles non-linear | Prone to overfitting | Small datasets, interpretability |\n",
    "| **Random Forest** | High accuracy, robust, feature importance | Less interpretable, slower | Production ML, high accuracy |\n",
    "\n",
    "### Production ML Checklist:\n",
    "\n",
    "- ‚úÖ **Data Quality**: Validation, missing value handling\n",
    "- ‚úÖ **Feature Engineering**: Scaling, encoding, selection\n",
    "- ‚úÖ **Model Selection**: Algorithm choice, hyperparameter tuning\n",
    "- ‚úÖ **Evaluation**: Multiple metrics, cross-validation\n",
    "- ‚úÖ **Deployment**: Serialization, versioning, monitoring\n",
    "- ‚úÖ **Maintenance**: Drift detection, retraining schedule\n",
    "\n",
    "### Business Impact:\n",
    "\n",
    "**Well-implemented classification can:**\n",
    "- **Reduce churn**: Target at-risk customers for retention\n",
    "- **Increase revenue**: Personalize marketing and offers\n",
    "- **Optimize operations**: Predict demand and resource needs\n",
    "- **Prevent fraud**: Identify suspicious transactions\n",
    "- **Improve customer experience**: Proactive service delivery\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you understand classification basics, you're ready for:\n",
    "\n",
    "1. **Regression Techniques** - Predicting continuous values\n",
    "2. **Clustering Algorithms** - Unsupervised learning patterns\n",
    "3. **Recommendation Systems** - Collaborative filtering\n",
    "4. **Feature Engineering** - Advanced feature creation\n",
    "5. **Model Evaluation** - Deep dive into metrics and validation\n",
    "6. **ML Pipeline Design** - Complex workflow orchestration\n",
    "\n",
    "**Classification is the foundation of supervised machine learning!**\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations! You now master classification with Spark MLlib!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
