{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview Challenge 8: Advanced DataFrame Operations & Window Functions\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "You are working with a large e-commerce dataset and need to perform complex analytics to understand customer behavior, product performance, and sales trends. Use PySpark DataFrame API and window functions to solve these business questions.\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "**Orders Table:**\n",
    "- `order_id` (string) - Unique order identifier\n",
    "- `customer_id` (string) - Customer who placed the order\n",
    "- `order_date` (date) - Date when order was placed\n",
    "- `product_id` (string) - Product that was ordered\n",
    "- `quantity` (integer) - Number of items ordered\n",
    "- `unit_price` (double) - Price per unit\n",
    "- `total_amount` (double) - Total order amount\n",
    "\n",
    "**Customers Table:**\n",
    "- `customer_id` (string)\n",
    "- `registration_date` (date)\n",
    "- `country` (string)\n",
    "- `customer_segment` (string)\n",
    "\n",
    "**Products Table:**\n",
    "- `product_id` (string)\n",
    "- `category` (string)\n",
    "- `subcategory` (string)\n",
    "- `brand` (string)\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. **Customer Analytics**\n",
    "   - Calculate customer lifetime value (LTV) using window functions\n",
    "   - Identify top 10 customers by total spending in each country\n",
    "   - Calculate customer retention rate (customers with orders in consecutive months)\n",
    "   - Find customers who haven't ordered in the last 30 days\n",
    "\n",
    "2. **Product Performance**\n",
    "   - Calculate product sales ranking within each category using window functions\n",
    "   - Identify products with declining sales (compare current month vs previous month)\n",
    "   - Calculate product category performance trends over time\n",
    "   - Find best-selling products by customer segment\n",
    "\n",
    "3. **Time Series Analysis**\n",
    "   - Calculate 7-day and 30-day moving averages for daily sales\n",
    "   - Identify sales seasonality patterns (monthly trends)\n",
    "   - Calculate year-over-year growth rates\n",
    "   - Find peak sales periods\n",
    "\n",
    "4. **Advanced Aggregations**\n",
    "   - Calculate percentile rankings for customer spending\n",
    "   - Implement custom aggregation functions\n",
    "   - Handle complex grouping and pivoting operations\n",
    "   - Calculate basket analysis metrics\n",
    "\n",
    "## Technical Requirements\n",
    "- Use PySpark DataFrame API extensively\n",
    "- Implement window functions for ranking, running totals, and moving averages\n",
    "- Use appropriate join strategies\n",
    "- Optimize for performance with proper partitioning\n",
    "- Handle null values and edge cases\n",
    "- Include comments explaining your approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AdvancedDataFrameChallenge\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "orders_data = [\n",
    "    ('ORD001', 'CUST001', '2023-01-15', 'PROD001', 2, 50.0, 100.0),\n",
    "    ('ORD002', 'CUST001', '2023-01-20', 'PROD002', 1, 75.0, 75.0),\n",
    "    ('ORD003', 'CUST002', '2023-01-18', 'PROD001', 3, 50.0, 150.0),\n",
    "    ('ORD004', 'CUST003', '2023-02-10', 'PROD003', 1, 200.0, 200.0),\n",
    "    ('ORD005', 'CUST001', '2023-02-15', 'PROD001', 1, 50.0, 50.0),\n",
    "    ('ORD006', 'CUST004', '2023-02-20', 'PROD002', 2, 75.0, 150.0),\n",
    "    ('ORD007', 'CUST002', '2023-03-05', 'PROD003', 1, 200.0, 200.0),\n",
    "    ('ORD008', 'CUST005', '2023-03-12', 'PROD001', 4, 50.0, 200.0)\n",
    "]\n",
    "\n",
    "customers_data = [\n",
    "    ('CUST001', '2020-01-15', 'US', 'Premium'),\n",
    "    ('CUST002', '2020-03-20', 'UK', 'Standard'),\n",
    "    ('CUST003', '2020-02-10', 'US', 'Premium'),\n",
    "    ('CUST004', '2020-04-05', 'DE', 'Standard'),\n",
    "    ('CUST005', '2020-01-30', 'US', 'Basic')\n",
    "]\n",
    "\n",
    "products_data = [\n",
    "    ('PROD001', 'Electronics', 'Laptops', 'BrandA'),\n",
    "    ('PROD002', 'Electronics', 'Phones', 'BrandB'),\n",
    "    ('PROD003', 'Home', 'Furniture', 'BrandC')\n",
    "]\n",
    "\n",
    "# Define schemas\n",
    "orders_schema = StructType([\n",
    "    StructField('order_id', StringType(), True),\n",
    "    StructField('customer_id', StringType(), True),\n",
    "    StructField('order_date', DateType(), True),\n",
    "    StructField('product_id', StringType(), True),\n",
    "    StructField('quantity', IntegerType(), True),\n",
    "    StructField('unit_price', DoubleType(), True),\n",
    "    StructField('total_amount', DoubleType(), True)\n",
    "])\n",
    "\n",
    "customers_schema = StructType([\n",
    "    StructField('customer_id', StringType(), True),\n",
    "    StructField('registration_date', DateType(), True),\n",
    "    StructField('country', StringType(), True),\n",
    "    StructField('customer_segment', StringType(), True)\n",
    "])\n",
    "\n",
    "products_schema = StructType([\n",
    "    StructField('product_id', StringType(), True),\n",
    "    StructField('category', StringType(), True),\n",
    "    StructField('subcategory', StringType(), True),\n",
    "    StructField('brand', StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrames\n",
    "orders_df = spark.createDataFrame(orders_data, orders_schema)\n",
    "customers_df = spark.createDataFrame(customers_data, customers_schema)\n",
    "products_df = spark.createDataFrame(products_data, products_schema)\n",
    "\n",
    "# Convert string dates to date type\n",
    "orders_df = orders_df.withColumn('order_date', to_date('order_date'))\n",
    "customers_df = customers_df.withColumn('registration_date', to_date('registration_date'))\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "orders_df.show(5)\n",
    "\n",
    "# === YOUR SOLUTION GOES HERE ===\n",
    "# Implement the advanced DataFrame operations\n",
    "\n",
    "# Task 1: Customer Analytics with Window Functions\n",
    "# 1a. Calculate customer lifetime value (running total)\n",
    "# 1b. Top 10 customers by spending per country\n",
    "# 1c. Customer retention (consecutive month orders)\n",
    "# 1d. Inactive customers (no orders in last 30 days)\n",
    "\n",
    "# Task 2: Product Performance Analysis\n",
    "# 2a. Product ranking within categories\n",
    "# 2b. Declining sales detection\n",
    "# 2c. Category performance trends\n",
    "# 2d. Segment-based product performance\n",
    "\n",
    "# Task 3: Time Series Analytics\n",
    "# 3a. Moving averages (7-day, 30-day)\n",
    "# 3b. Monthly seasonality patterns\n",
    "# 3c. Year-over-year growth\n",
    "# 3d. Peak sales periods\n",
    "\n",
    "# Task 4: Advanced Aggregations\n",
    "# 4a. Percentile rankings\n",
    "# 4b. Custom aggregation functions\n",
    "# 4c. Complex grouping operations\n",
    "# 4d. Basket analysis metrics\n",
    "\n",
    "print(\"Implement your advanced DataFrame operations above!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
